# NNUE Developer Guide

This document explains how Fire’s NNUE evaluation works and how to modify or integrate it. 
It is written for engine developers who want both the big picture and exact function responsibilities.

**Diagrams:**
- **Data Flow:** `docs/nnue_flow.png` (updated text uses “indices”)
- **Orientation Mapping:** `docs/nnue_orientation.png`

---

## 1. What NNUE Is (in this engine)

- **Feature format:** HalfKP = `(king_square, piece_square, piece_type)`
- **Orientation:** The board is flipped for black so the network sees a “white-like” perspective for both sides.
- **Accumulator:** A per-color vector (256 lanes each) that sums feature transformer biases + weights for active features. 
  It supports incremental updates via a small **dirty piece** record.
- **Dense head:** `32 -> 32 -> 1` fully connected layers, quantized int8 inputs/weights with int16/int32 accumulators, AVX2 accelerated.

**Key files**
- `nnue.h`: public types, constants, network storage, and API
- `nnue.cpp`: loading, feature transformer, accumulator updates, dense layers

---

## 2. Data Flow (high level)

pieces[] + squares[] (from board) and dirty_piece (last move) feed into:

Accumulator (per color, 256 lanes)
    ↓
transform() → int8 features (512)
    ↓
affine_txfm (hidden1, 32) → affine_txfm (hidden2, 32, ReLU)
    ↓
affine_propagate (32 → 1)
    ↓
score / fv_scale

- **Indices**: The HalfKP *feature indices* are generated by `make_index()` and are the rows we add/subtract in the accumulator during full build or incremental updates.

See the diagram: `docs/nnue_flow.png`

---

## 3. Orientation

To share weights across colors, we orient squares for black:

```cpp
int orient(const int c, const int s) {
  return s ^ (c == white ? 0x00 : 0x3f);
}
```

- `0x3f` = `111111b` flips all 6 bits of a 0..63 square index (180° rotation).
- Black’s perspective is rotated so their back rank “looks like” white’s.

See the diagram: `docs/nnue_orientation.png`

---

## 4. Core Data Structures

**board** (minimal view NNUE needs)
```cpp
struct board {
  int player;         // 0 = white, 1 = black
  int* pieces;        // pieces[0] = wking, pieces[1] = bking; others from index 2; 0-terminated
  int* squares;       // parallel to pieces[]
  nnue_data* nnue[3]; // current and up to two previous entries for incrementals
};
```

**nnue_data**
```cpp
struct nnue_data {
  accumulator accu;        // accumulation buffers (two halves)
  dirty_piece dirty_piece; // up to 3 changes (from/to/pc)
};
```

**accumulator**
```cpp
struct accumulator {
  alignas(64) int16_t accumulation[2][256]; // [color][lane]
  int computed_accumulation;                // 1 => valid for this position
};
```

**dirty_piece**
- `dirty_num` in `[0..3]`
- arrays `pc[i]`, `from[i]`, `to[i]` per entry
- `from[i] == 64` or `to[i] == 64` when not applicable
- **Kings are excluded**: king movement triggers a **reset** for that color

---

## 5. Feature Indices (HalfKP)

Indices come from:

```
index = orient(color, piece_square)
      + piece_to_index[color][piece_type]
      + ps_end * oriented_king_square
```

- Built by `make_index(c, s, pc, ksq)`
- Enumerated in full by `half_kp_append_active_indices`
- Enumerated incrementally by `half_kp_append_changed_indices`

---

## 6. Accumulator: Full Build vs Incremental Update

### 6.1 Full Build: `refresh_accumulator(const board*)`
- Creates the complete set of **active indices** per color.
- Initializes each tile of 256 lanes with `ft_biases`, then **adds** the rows from `ft_weights` for each active index.

When is it used?
- On first evaluation of a node (no previous accumulation)
- When a **king moves** (orientation bucket changes → must rebuild)

### 6.2 Incremental: `update_accumulator(const board*)`
- Finds a valid previous accumulation in `pos->nnue[1]` or `pos->nnue[2]`.
- Computes per-color **removed** and **added** index lists using `dirty_piece`.
- If **king moved** for that color, resets that color’s tile to `ft_biases` and then adds all current features.
- Otherwise:
  - Starts from previous tile
  - **Subtracts** `ft_weights[row]` for removed indices
  - **Adds** `ft_weights[row]` for added indices

Returns:
- `true` if incrementally updated
- `false` if no valid previous base exists → caller should call `refresh_accumulator()`

### 6.3 Choosing the Path
```cpp
if (!update_accumulator(pos)) {
  refresh_accumulator(pos);
}
```

---

## 7. Transform: Packing to int8 + Output Mask

```cpp
void transform(const board* pos, clipped_t* output, mask_t* out_mask);
```

- Packs per-color `int16` accumulators to `int8` features.
- Writes a bitmask marking **positive** lanes (`> 0`) for sparse traversal.
- Order is **side-to-move first**:
  - `output[0..255]` = `player`
  - `output[256..511]` = `!player`

---

## 8. Dense Layers (AVX2)

### 8.1 Hidden Layers: `affine_txfm(...)`
- Consumes `int8` inputs with an **input mask** (sparse iteration).
- Accumulates into 32 outputs using four AVX2 accumulators (packed).
- Two inputs are paired (low/high bytes) for `_mm256_maddubs_epi16`.
- Right-shift and pack down to `int8`.
- Modes:
  - `pack8_and_calc_mask = true` → emit **positive output mask** for the next layer
  - `false` → apply **ReLU** (`max(x, 0)`) in place

**Key idea:** iterate only active input **indices** via `next_idx()` from the mask to avoid zero-work.

### 8.2 Output Layer: `affine_propagate(...)`
- `32 → 1` scalar using maddubs + madd + lane reductions
- Returns `int32` sum + bias
- The final score is `raw / fv_scale`

---

## 9. Network Loading and Verification

### 9.1 `nnue_init(const char* eval_file)`
- Loads a serialized network from disk or uses an embedded blob (non-MSVC builds with `NNUE_EMBEDDED`).
- Calls `verify_net(...)` to assert:
  - exact size
  - header/version magics at fixed offsets
- On success, `init_weights(...)` fills:
  - Feature transformer: `ft_biases`, `ft_weights`
  - Hidden layers: `hidden{1,2}_biases`, `hidden{1,2}_weights`
  - Output: `output_biases`, `output_weights`
- Some bias lanes are **permuted** to match the packed weight layout.

---

## 10. Evaluation Entry Points

### 10.1 `int nnue_evaluate_pos(const board* pos)`
```
transform → hidden1 (sparse) → hidden2 (dense + ReLU) → output → scale
```

### 10.2 `int nnue_evaluate(int player, int* pieces, int* squares)`
- Convenience wrapper that builds a minimal `board` and evaluates it.

---

## 11. Integration Notes

- **pieces[] layout:** index 0 = white king, 1 = black king, from 2 onward all others; end with 0.
- **squares[]:** parallel to pieces[]; same indexing.
- **dirty_piece:** fill with up to 3 changes since the previous position.
- **King moves:** cause `reset[color] = true` inside incremental update.
- **Threading:** The NNUE accumulators live in `nnue_data` objects. Keep a small ring per node or per stack frame so you can delta from prior plies. Do not share a single accumulator across threads without careful locking.

---

## 12. Debugging Tips

- **Divide mismatch?** Run a perft of your movegen first; NNUE depends on correct piece lists and king squares.
- **Wrong sign or scaling?** Check `fv_scale` and confirm that your GUI expects centipawns.
- **No speedup from incrementals?** Verify `dirty_piece` is filled correctly and `nnue[1]`/`nnue[2]` point to the previous positions’ `nnue_data`.
- **Weird black/white asymmetry?** Recheck `orient()` usage and the king square used in `make_index()`.

---

## 13. Minimal Example (pseudo-code)

```cpp
// Before search:
nnue_init(nnue_file);

// On entering a node:
nnue_data cur;
cur.accu.computed_accumulation = 0;
board b { player, pieces, squares, { &cur, prev1, prev2 } };

int score = nnue_evaluate_pos(&b); // centipawns after scaling
```

---

## 14. Performance Notes

- AVX2 packed math: `_mm256_maddubs_epi16` + `_mm256_madd_epi16`
- Sparse traversal via masks to skip zero inputs
- 64-byte alignments for weight/accumulator tiles
- Tile size: `TILE_HEIGHT = num_regs * simd_width / 16`
- Keep `pieces[]`/`squares[]` contiguous and hot in cache

---

## 15. API Reference (quick)

- `int nnue_init(const char* file);`
- `int nnue_evaluate_pos(const board* pos);`
- `int nnue_evaluate(int player, int* pieces, int* squares);`

Supporting (internal):
- `refresh_accumulator`, `update_accumulator`, `transform`
- `affine_txfm`, `affine_propagate`
- `open_file`, `map_file`, `unmap_file`, `verify_net`, `init_weights`

---

## 16. Glossary

- **Indices:** Integer feature row selectors produced by `make_index()`.
- **HalfKP:** Feature scheme combining king square (“K”) with piece+square (“P”).
- **Accumulator:** Per-color 256-lane sum of biases + active rows.
- **ReLU:** `max(x, 0)`; used at the second hidden layer output.
- **Mask:** Bitset indicating positive activations, used to drive sparse traversal.
